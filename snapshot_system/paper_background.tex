\section{Background and Design Considerations}
\label{sect:background}

Figure~\ref{fig:collocated} illustrates a converged cloud architecture where
each commodity server hosts a number of virtual machines and storage of these servers
is clustered using a distributed file system~\cite{googlefs03,hdfs10}.
Each physical machine 
each instance of a guest operating system runs on a virtual machine, accessing virtual hard disks 
represented as virtual disk image files in the host operating system.
For VM snapshot backup, file-level semantics are normally not provided.
Snapshot operations take place at the virtual device driver level, which
means no fine-grained file system metadata can be used to determine the changed data. 
%This architecture does not use a seperate  backup facility for a lower cost and 
%reduces the network bandwidth consumption in transferring the raw data for backup. 
A backup sevice may collocate with other cloud services on these commodity servers and 
stores deduplicated data  in  the storage in this cluster or in
a seperate storage cluster.


%runs a backup service and 


%As discussed earlier, collocating a backup service on the existing
%cloud cluster avoids the extra cost to acquire a dedicated backup facility

\begin{figure}[htb]
    \centering
    \includegraphics[width=3in]{images/colocated-arch}
    \caption{VM snapshot backup running on a converged cloud cluster.}
    \label{fig:collocated}
\end{figure}

File backup systems have been developed to use content fingerprints to identify duplicate
content~\cite{venti02,Rhea2008}.  It is expensive to compare a large number of chunk fingerprints
and several techniques have been proposed to speedup. For example, the data domain method ~\cite{bottleneck08} 
uses  an in-memory Bloom filter and a prefetching cache for data chunks  which may be
accessed.  
%An improvement to this work with parallelization is in ~\cite{MAD210,DEBAR}.
The approximation techniques are studied in~\cite{extreme_binning09,Guo2011,WeiZhangIEEE}  
to reduce memory requirements with the tradeoff of a reduced deduplication ratio.
Additional inline deduplication techniques are studied in ~\cite{sparseindex09,Guo2011,Srinivasan2012}
and a parallel batch solution for cluster-based deduplication is 
studied in ~\cite{wei2013}. 
All of the above approaches have focused on optimization of deduplication
efficiency, and none of them have considered the impact
of deduplication on fault tolerance in a cloud  cluster environment considered in this paper.
Our consideration is discussed below.
%VM dependence minimization during deduplication and file system block management.
\begin{itemize}
\item {\em Deduplication localization.}
Because a data chunk is compared with fingerprints collected from all VMs during
the deduplication process, only one copy of duplicates is stored in the storage,
this artificially creates data dependencies among different VM users. 
Content sharing via deduplication affects fault isolation since machine failures happen periodically 
in a large-scale cloud and
loss of a small number of shared data chunks can 
cause the unavailability of snapshots for a large number of virtual machines.
Localizing the impact of deduplication can increase fault isolation and resilience.
Thus from the fault tolerance point of view,  duplicate sharing among multiple VMs is 
discouraged. 
Another disadvantage of sharing is that it complicates snapshot deletion, 
which  occurs frequently when snapshots expire regularly. 
The mark-and-sweep approach~\cite{Guo2011,Fabiano2013}  is effective for deletion, but still carries a significant cost
to count if a data chunk is still shared by other snapshots. 
Localizing deduplication can  minimize data sharing and simplify deletion while sacrificing 
deduplication efficiency, and  can facilitate parallel execution of snapshot operations.
\item{\em  Management of file system blocks.}
The file system block (FSB) size in a distributed file system such as  Hadoop and Google file system
 is uniform and large (e.g.  64MB),
while the data chunk in a typical deduplication system is of a non-uniform size with 4KB or 8KB on average.
Packaging data chunks to an FSB can create more data dependencies among VMs
since a file system block can be shared by even more VMs.
Thus we need to consider a minimum association of FSBs to VMs in the packaging process.

\item {\em Low resource usage in a nondedicated cloud cluster.}
When a backup service collocates with other cloud services as illustrated in Figure~\ref{fig:collocated},
low resource usage of deduplication is desired so that
there is  a minimal impact to the other existing cloud services.
The key resource for global comparison  is memory for storing the fingerprints.
During snapshot deltion, reference counting for all unique blocks used in all VMs requires a significant resource usage
too.  Thus we seek for the low-profile techniques with approximation and low resource consumption. 
\end{itemize}

We call the traditional deduplication approach as   VM-oblivious (VO)
because they compare fingerprints of snapshots without consideration of VMs.
With the above  considerations in mind, we study a 
VM-centric approach (called VC)
for a collocated backup service with resource usage friendly
to the existing applications in a converged clustr architecture.  

In designing a VC duplication solution, we have considered and adopted some of
the following previously-developed techniques.
1)
{\em Changed block Tracking}.
VM snapshots can be  backed up  incrementally by identifying data segments that have
changed from the previous version of the snapshot~\cite{Clements2009,Vrable2009,TanIPDPS2011}.
Such a scheme  is  VM-centric since deduplication is localized. 
We are seeking for a tradeoff since 
global signature comparison can deliver additional compression~\cite{Guo2011,Dong2011,extreme_binning09}.
2) {\em Stateless  Data Routing}.
One approach for scalable duplicate comparison is to use a content-based hash
partitioning algorithm called stateless data routing by Dong et al.~\cite{Dong2011} 
Stateless data routing divides the deduplication work with a similarity approximation. This work 
is similar to Extreme Binning by Bhagwat et al.~\cite{extreme_binning09} and 
each request is routed  to a machine which holds
a Bloom filter  or can fetch on-disk index for additional comparison.
While this approach is VM-oblivious, it motivates us to  use  a combined signature of a dataset to narrow
VM-specific local search.
3) {\em Sampled Index}.
One effective approach that reduces memory usage is 
to use a sampled index with prefetching, proposed  by Guo and Efstathopoulos\cite{Guo2011}. 
The algorithm is VM oblivious and it is not easy  to adopt for a distributed architecture. 
To use a distributed memory version of the sampled index, every deduplication request
may access a remote machine for index lookup and the overall overhead of access latency for all requests
can be significant.  


We will first discuss and analyze the integration of the VM-centric deduplication strategies with fault isolation, 
and discuss snapshot deletion support, then present an implementation design. 
