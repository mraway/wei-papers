

\begin{table}[htb]
\centering
\begin{tabular}{|c|c|c|c|}
    \hline 
%& \multicolumn{4}{|c|}{VC}  & VO \\ \hline
	    &Time p=50 & Time p=100 & Memory \\
	    &(hours)  & (hours) & (GB) \\
\hline
Mark-sweep  & 35.9  &  84.3  & 1.2--3 \\
\hline
Grouped &     18.6    & 43.6   & 1.2--3 \\
mark-sweep &        &    &  \\
\hline
VC w/o sum &  0.7     & 0.82   & 0.05 -- 1.96 \\
\hline
VC  &  0.012      & 0.014   & 0.015  \\
\hline
VC Repair  &  0.7      & 0.82   & 0.05 -- 1.96 \\
\hline
    \end{tabular}
    \caption{ Processing time and memory usage  for
deletion}  
    \label{tab:deletion-cmp}
\end{table}

Table~\ref{tab:deletion-cmp}   lists a comparison of processing time and memory usage
using the four deletion approaches when $p=100$ and $p=50$. These four 
methods are 1) the standard mark-sweep method. 2) Grouped mark-sweep~\cite{Guo2011}. 
3)   VC summary vectors. 4) VC with summary vectors.
The I/O speed for the backend distributed file system is about 50MB/second
and the speed drops to about 25MB/second when
when 100 machines read the backend file system concurrently due to the network
contention. We explain the results for $p=100$ below and notice each physical machine hosts 25VMs on average. The explanation for $p=50$ is similar.

For the mark-sweep approach on $p=100$, a physical machine is responsible of 
reading the metadata of non-deduplicated chunks used in the hosted 
virtual machines and keeping the usage index table in the memory.
Then all machines read the meta data 
of snapshots in parallel and mark the usage of referenced chunks
in the usage table.
This process is repeated 100 times for all physical machines.
The memory allocated at each physical machine is for the 
chunk usage table of 25 VMs. The average size is 1.2GB and the maximum is
3GB. If we reduce the size of  the usage table at each machine, 
then there are more iterations to mark all data and it 
will take longer time.    
For the grouped mark-sweep, about 50\% of snapshot meta reading can be 
avoided in assessing the reference usage of non-duplicate chunks. 
Thus it takes 50\% less time, which is about 43 hours, but the 
memory requirement does not decrease.

For VC without summary vectors, all physical machines conduct the mark-sweep process in parallel, 
but each machine only handles one VM at time and 
the scope of meta data comparison is controlled within the single VM.
Popular chunks are excluded. The average memory usage is the index size of 
non-deduplicated VM chunks, which is about 50MB on average and the largest
size is 1.96GB. 
For VC with summary vectors, each physical machine loads
the VM snapshots and only needs to compare with the summary vectors.
The memory usage is controlled within 15MB for hosting the summary vectors
and small buffers. The deletion time is reduced to less than 1 minute.
The periodic leakage repair still takes about 0.83 hours while using
an average of 50MB memory. For  few big VMs in a skewed data distribution,
the repair uses upto 1.9GB memory.
Such a repair does not occur often (e.g. occurs every 19.6 days as discussed in Section~\ref{sect:delete}). 


